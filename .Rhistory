knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(dplyr)
library(ggplot2)
library(stringr)
file_path <- 'IAC_Database_20240514.xlsx'
sheet_names <- excel_sheets(file_path)
# Initialize a list to hold all data frames
data_frames <- list()
# Loop through each sheet name and read the sheet into a data frame
for (sheet_name in sheet_names) {
data_frames[[sheet_name]] <- read_excel(file_path, sheet = sheet_name, guess_max = 10000)
}
# Example: Access the data frame for the first sheet
df_first_sheet <- data_frames[[sheet_names[1]]]
df_first_sheet
str_flatten_comma((colnames(data_frames[['ASSESS']]), last = ", and ")
str_flatten_comma((colnames(data_frames[['ASSESS']]) last = ", and ")
str_flatten_comma((colnames(data_frames[['ASSESS']]), last = ", and ")
`r str_flatten_comma((colnames(data_frames[['ASSESS']]), last = ', and ')`
print(data_frames[['Terms']])
for (i in 1:nrow(data_frames[['Terms']])){
print(data_frames[['Terms']]$`ASSESS Terms`)
}
print(data_frames[['Terms']])
for (i in 1:nrow(data_frames[['Terms']])){
cat(data_frames[['Terms']]$`ASSESS Terms`[i],": ", data_frames[['Terms']][2][i] )
}
for (i in 1:nrow(data_frames[['Terms']])){
print(data_frames[['Terms']]$`ASSESS Terms`[i],": ", data_frames[['Terms']][2][i])
}
for (i in 1:nrow(data_frames[['Terms']])){
print(data_frames[['Terms']]$`ASSESS Terms`[i],": ", data_frames[['Terms']][[2]][i])
}
for (i in 1:nrow(data_frames[['Terms']])){
print(data_frames[['Terms']][['ASSESS Terms']][i] ,": ", data_frames[['Terms']][[2]][i])
}
for (i in 1:nrow(data_frames[['Terms']])){
print(data_frames[['Terms']][['ASSESS Terms']][i] )#,": ", data_frames[['Terms']][[2]][i])
}
print(data_frames[['Terms']])
for (i in 1:nrow(data_frames[['Terms']])){
cat(data_frames[['Terms']][['ASSESS Terms']][i] )#,": ", data_frames[['Terms']][[2]][i])
}
print(data_frames[['Terms']])
for (i in 1:nrow(data_frames[['Terms']])){
cat(data_frames[['Terms']][['ASSESS Terms']][i] ,": ")#, data_frames[['Terms']][[2]][i])
}
print(data_frames[['Terms']])
for (i in 1:nrow(data_frames[['Terms']])){
cat(data_frames[['Terms']][['ASSESS Terms']][i],": ", data_frames[['Terms']][[2]][i])
}
print(data_frames[['Terms']])
for (i in 1:nrow(!is.na(data_frames[['Terms']])){
for (i in 1:nrow(!is.na(data_frames[['Terms']])){
for (i in 1:nrow(!is.na(data_frames[['Terms']]))){
cat(data_frames[['Terms']][['RECC Terms']][i],": ", data_frames[['Terms']][[5]][i], '\n')
}
!is.na(data_frames[['Terms']]
!is.na(data_frames[['Terms']]
(!is.na(data_frames[['Terms']])
for (i in 1:nrow(na.omit(data_frames[['Terms']]))){
for (i in 1:nrow(na.omit(data_frames[['Terms']]))){
cat(data_frames[['Terms']][['RECC Terms']][i],": ", data_frames[['Terms']][[5]][i], '\n')
}
for (i in 1:nrow(na.omit(data_frames[['Terms']]))){
cat(data_frames[['Terms']][['RECC Terms']][i],": ", data_frames[['Terms']][[5]][i], '\n')
}
for (i in 1:nrow(!is.na(data_frames[['Terms']]))){
cat(data_frames[['Terms']][['RECC Terms']][i],": ", data_frames[['Terms']][[5]][i], '\n')
}
for (i in 1:nrow(na.omit(data_frames[['Terms']]))){
cat(data_frames[['Terms']][['RECC Terms']][i],": ", data_frames[['Terms']][[5]][i], '\n')
}
for (i in 1:nrow(na.omit(data_frames[['Terms']]))){
cat(data_frames[['Terms']][['RECC Terms']][i],": ", data_frames[['Terms']][[5]][i], '\n')
}
for (i in 1:nrow(data_frames[['Terms']])){
cat(data_frames[['Terms']][['RECC Terms']][i],": ", data_frames[['Terms']][[5]][i], '\n')
}
for (i in 1:nrow(data_frames[['Terms']])) {
term <- data_frames[['Terms']][['RECC Terms']][i]
description <- data_frames[['Terms']][[5]][i]
if (!is.na(term) && !is.na(description)) {
cat(term, ": ", description, '\n')
}
}
n(sheet_names)
This analysis is significant for several reasons. It can inform policymakers and stakeholders about the effectiveness of the IAC program and help shape future energy efficiency initiatives. Manufacturers can benefit from understanding which recommendations have been most effective in similar contexts, aiding in the adoption of best practices. Furthermore, this study contributes to broader efforts to reduce the environmental impact of manufacturing industries, aligning with global sustainability goals. By identifying cost-saving measures, this research can also help manufacturers reduce operational costs, thereby improving their competitiveness and financial health. Ultimately, this analysis will provide valuable insights into the IAC program's impact, guiding future improvements and fostering a more sustainable manufacturing sector.
length(sheet_names)
for (i in 1:nrow(data_frames[['Terms']])){
cat(data_frames[['Terms']][['ASSESS Terms']][i],": ", data_frames[['Terms']][[2]][i], '\n')
}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("tidyverse")
library(readxl)
library(dplyr)
library(ggplot2)
library(stringr)
library(maps)
file_path <- 'IAC_Database_20240514.xlsx'
sheet_names <- excel_sheets(file_path)
naics_codes <-  read_excel("2-6 digit_2022_Codes.xlsx")
# names(naics_codes)
# naics_codes <- read.csv("naics.csv")
naics_codes <- naics_codes %>%
select("2022 NAICS US   Code", "2022 NAICS US Title")
names(naics_codes)[names(naics_codes) == "2022 NAICS US   Code"] <- 'NAICS'
names(naics_codes)[names(naics_codes) == "2022 NAICS US Title"] <- 'US_TITLE'
naics_codes$NAICS <- asNumeric(naics_codes$NAICS)
file_path <- 'IAC_Database_20240514.xlsx'
sheet_names <- excel_sheets(file_path)
naics_codes <-  read_excel("2-6 digit_2022_Codes.xlsx")
# names(naics_codes)
# naics_codes <- read.csv("naics.csv")
naics_codes <- naics_codes %>%
select("2022 NAICS US   Code", "2022 NAICS US Title")
names(naics_codes)[names(naics_codes) == "2022 NAICS US   Code"] <- 'NAICS'
names(naics_codes)[names(naics_codes) == "2022 NAICS US Title"] <- 'US_TITLE'
naics_codes$NAICS <- as.numeric(naics_codes$NAICS)
head(naics_codes)
# Initialize a list to hold all data frames
data_frames <- list()
# Loop through each sheet name and read the sheet into a data frame
for (sheet_name in sheet_names) {
data_frames[[sheet_name]] <- read_excel(file_path, sheet = sheet_name, guess_max = 10000)
}
head(data_frames)
knitr::opts_chunk$set(echo = TRUE)
#install.packages("tidyverse")
library(readxl)
library(dplyr)
library(ggplot2)
library(stringr)
library(maps)
file_path <- 'IAC_Database_20240514.xlsx'
sheet_names <- excel_sheets(file_path)
naics_codes <-  read_excel("2-6 digit_2022_Codes.xlsx")
# names(naics_codes)
# naics_codes <- read.csv("naics.csv")
naics_codes <- naics_codes %>%
select("2022 NAICS US   Code", "2022 NAICS US Title")
names(naics_codes)[names(naics_codes) == "2022 NAICS US   Code"] <- 'NAICS'
names(naics_codes)[names(naics_codes) == "2022 NAICS US Title"] <- 'US_TITLE'
naics_codes$NAICS <- as.numeric(naics_codes$NAICS)
head(naics_codes)
# Initialize a list to hold all data frames
data_frames <- list()
# Loop through each sheet name and read the sheet into a data frame
for (sheet_name in sheet_names) {
data_frames[[sheet_name]] <- read_excel(file_path, sheet = sheet_name, guess_max = 10000)
}
head(data_frames)
for (i in 1:nrow(data_frames[['Terms']])){
cat(data_frames[['Terms']][['ASSESS Terms']][i],": ", data_frames[['Terms']][[2]][i], '\n')
}
for (i in 1:nrow(data_frames[['Terms']])) {
term <- data_frames[['Terms']][['RECC Terms']][i]
description <- data_frames[['Terms']][[5]][i]
if (!is.na(term) && !is.na(description)) {
cat(term, ": ", description, '\n')
}
}
all_reccs <- data_frame()
for(sheet_name in sheet_names[2:7]){
print(sheet_name)
all_reccs <- bind_rows(all_reccs, data_frames[[sheet_name]])
}
nrow(all_reccs)
print(sheet_names)
joined_frames <- inner_join(data_frames[["ASSESS"]], all_reccs, "ID")
joined_frames <- joined_frames %>%
mutate(STATE = toupper(STATE)) %>%
select(!FY.y)
names(joined_frames)[names(joined_frames) == 'FY.x'] <- 'FY'
joined_frames <- left_join(joined_frames, naics_codes, "NAICS")
tail(joined_frames)
# Bar Plot of Total Energy Costs by Plant
# Calculate total energy costs for each center
energy_cost_columns <- c("EC_plant_cost", "E2_plant_cost", "E3_plant_cost", "E4_plant_cost", "E5_plant_cost",
"E6_plant_cost", "E7_plant_cost", "E8_plant_cost", "E9_plant_cost", "E10_plant_cost",
"E11_plant_cost", "E12_plant_cost")
joined_frames %>%
filter(is.na(PSAVED)) %>%
nrow()
total_saving <- joined_frames %>%
select(CENTER, PSAVED) %>%
group_by(CENTER) %>%
summarize(TOTALPSAVED = mean(PSAVED)) %>%
filter(TOTALPSAVED > 0)
total_saving %>%
ggplot(aes(x = CENTER, y = TOTALPSAVED)) +
geom_bar(stat = "identity", fill = "skyblue") +
labs(title = "Total Energy Costs by Plant",
x = "Center",
y = "Total Energy Cost") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Using only the asessments found in washington
joined_frames %>%
filter(STATE == "WA") %>%
group_by(CENTER) %>%
summarize(TOTALPSAVED = mean(PSAVED, na.rm = TRUE)) %>%
ggplot(aes(x = CENTER, y = TOTALPSAVED)) +
geom_bar(stat = "identity", fill = "skyblue") +
labs(title = "Washington Centers by Primary Savings",
x = "Center",
y = "Total PRimary Energy Savings") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Using only the asessments found in washington
joined_frames %>%
filter(STATE == "WA") %>%
select(CENTER, PSOURCCODE) %>%
group_by(CENTER) %>%
#count(PSOURCCODE, na.rm = TRUE) %>%
# Need a little help on this one, need the amounts on the side
ggplot(aes(x = factor(CENTER), y = PSOURCCODE, fill = PSOURCCODE)) +
geom_bar(stat = "identity", , position = position_dodge()) +
labs(title = "Washington Centers by Primary Savings",
x = "Center",
y = "Total PRimary Energy Savings") +
#scale_fill_manual(values = c("purple", "gold"), scale = PSOURCCODE)
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
joined_frames %>%
filter(STATE == "WA") %>%
group_by(CENTER) %>%
count(PSOURCCODE, na.rm = TRUE) %>%
filter(n > 25) %>%
ggplot(aes(x = CENTER, y = n, fill = PSOURCCODE)) +
geom_bar(stat = "identity", , position = position_dodge()) +
labs(title = "Washington Centers by Primary Resource",
x = "Center",
y = "Count of Reports for Energy of that Type",
)
#scale_fill_manual(values = c("purple", "gold"), scale = PSOURCCODE)
# theme_minimal() +
# theme(axis.text.x = element_text(angle = 45, hjust = 1))
# select(CENTER, PSOURCCODE) %>%
# summarize(code_count = count(PSOURCCODE, na.rm = TRUE))
# Highest count NAICS code, grouped by Center
joined_frames %>%
filter(STATE == "WA") %>%
select(CENTER, NAICS, STATE, US_TITLE) %>%
group_by(CENTER) %>%
na.omit() %>%
count(US_TITLE, na.rm = TRUE) %>%
filter(rank(desc(n)) < 5) %>%
# Change the fill name to the actual product
ggplot(aes(x = CENTER, y = n, fill = factor(US_TITLE))) +
geom_bar(stat = "identity", position = position_dodge()) +
labs(title = "Washington Centers by Primary Resource",
x = "Center",
y = "Count of Reports for Energy of that Type",
fill = "NAICS Code"
)
# assess_data <- read_excel("path/to/IAC_Database_20240514.xlsx", sheet = "ASSESS")
state_summary <- joined_frames %>%
group_by(STATE) %>%
summarise(assessments = n(), .groups = 'drop')  # Count of assessments
states_map <- map_data("state")
state_summary$region <- tolower(state_summary$STATE) # Make sure state names match
map_data <- merge(states_map, state_summary, by = "region", all.x = TRUE)
choropleth_map <- ggplot(map_data, aes(long, lat, group = group, fill = assessments)) +
geom_polygon(color = "white") +
coord_fixed(1.3) +
labs(fill = "Number of Assessments") +
ggtitle("Number of Assessments by State") +
theme_minimal()
#
# print(choropleth_map)
# ggsave("state_choropleth_map_assessments.png", plot = choropleth_map)
# assess_data <- read_excel("path/to/IAC_Database_20240514.xlsx", sheet = "ASSESS")
state_summary <- joined_frames %>%
group_by(STATE) %>%
summarise(assessments = n(), .groups = 'drop')  # Count of assessments
states_map <- map_data("state")
state_summary$region <- tolower(state_summary$STATE) # Make sure state names match
map_data <- merge(states_map, state_summary, by = "region", all.x = TRUE)
ggplot(map_data, aes(long, lat, group = group, fill = assessments)) +
geom_polygon(color = "white") +
coord_fixed(1.3) +
labs(fill = "Number of Assessments") +
ggtitle("Number of Assessments by State") +
theme_minimal()
#
# print(choropleth_map)
# ggsave("state_choropleth_map_assessments.png", plot = choropleth_map)
# assess_data <- read_excel("path/to/IAC_Database_20240514.xlsx", sheet = "ASSESS")
state_summary <- joined_frames %>%
group_by(STATE) %>%
summarise(assessments = n(), .groups = 'drop')  # Count of assessments
state_summary
states_map <- map_data("state")
state_summary$region <- tolower(state_summary$STATE) # Make sure state names match
map_data <- merge(states_map, state_summary, by = "region", all.x = TRUE)
ggplot(map_data, aes(long, lat, group = group, fill = assessments)) +
geom_polygon(color = "white") +
coord_fixed(1.3) +
labs(fill = "Number of Assessments") +
ggtitle("Number of Assessments by State") +
theme_minimal()
#
# print(choropleth_map)
# ggsave("state_choropleth_map_assessments.png", plot = choropleth_map)
# assess_data <- read_excel("path/to/IAC_Database_20240514.xlsx", sheet = "ASSESS")
state_summary <- joined_frames %>%
group_by(STATE) %>%
summarise(assessments = n(), .groups = 'drop')  # Count of assessments
state_summary
states_map <- map_data("state")
state_summary$region <- tolower(state_summary$STATE) # Make sure state names match
map_data <- merge(states_map, state_summary, by = "region", all.x = TRUE)
ggplot(map_data, aes(long, lat, group = group, fill = assessments)) +
geom_polygon(color = "white") +
coord_fixed(1.3) +
labs(fill = "Number of Assessments") +
ggtitle("Number of Assessments by State") +
theme_minimal()
#
# print(choropleth_map)
# ggsave("state_choropleth_map_assessments.png", plot = choropleth_map)
# assess_data <- read_excel("path/to/IAC_Database_20240514.xlsx", sheet = "ASSESS")
state_summary <- joined_frames %>%
group_by(STATE) %>%
summarise(assessments = n(), .groups = 'drop')  # Count of assessments
state_summary
states_map <- map_data("state")
state_summary$region <- tolower(state_summary$STATE) # Make sure state names match
map_data <- merge(states_map, state_summary, by = "region", all.x = TRUE)
ggplot(map_data, aes(long, lat, group = group, fill = assessments)) +
geom_polygon(color = "white") +
scale_fill_gradient(low = "white", high = "blue", na.value = "grey") +  # Add this to handle NAs
coord_fixed(1.3) +
labs(fill = "Number of Assessments") +
ggtitle("Number of Assessments by State") +
theme_minimal()
#
# print(choropleth_map)
# ggsave("state_choropleth_map_assessments.png", plot = choropleth_map)
# assess_data <- read_excel("path/to/IAC_Database_20240514.xlsx", sheet = "ASSESS")
state_summary <- joined_frames %>%
group_by(STATE) %>%
summarise(assessments = n(), .groups = 'drop')  # Count of assessments
state_summary$region <- tolower(state_summary$STATE)
# Get the state map data
states_map <- map_data("state")
# Debug: Check if there's a mismatch in state names
# This will print any state names from your data not found in the map data
setdiff(state_summary$region, unique(states_map$region))
# Merge the summarized data with the map data and check how many are NA after merge
map_data <- merge(states_map, state_summary, by = "region", all.x = TRUE)
table(is.na(map_data$assessments))
```{r}
# assess_data <- read_excel("path/to/IAC_Database_20240514.xlsx", sheet = "ASSESS")
state_summary <- joined_frames %>%
group_by(STATE) %>%
summarise(assessments = n(), .groups = 'drop')  # Count of assessments
state_summary
states_map <- map_data("state")
state_summary$region <- tolower(state_summary$STATE)
# Get the state map data
states_map <- map_data("state")
# Debug: Check if there's a mismatch in state names
# This will print any state names from your data not found in the map data
setdiff(state_summary$region, unique(states_map$region))
# Merge the summarized data with the map data and check how many are NA after merge
map_data <- merge(states_map, state_summary, by = "region", all.x = TRUE)
table(is.na(map_data$assessments))
# Create the choropleth map
ggplot(map_data, aes(long, lat, group = group, fill = assessments)) +
geom_polygon(color = "white") +
scale_fill_gradient(low = "white", high = "blue", na.value = "grey") +  # Add this to handle NAs
coord_fixed(1.3) +
labs(fill = "Number of Assessments") +
ggtitle("Number of Assessments by State") +
theme_minimal()
# assess_data <- read_excel("path/to/IAC_Database_20240514.xlsx", sheet = "ASSESS")
state_summary <- joined_frames %>%
group_by(STATE) %>%
summarise(assessments = n(), .groups = 'drop')  # Count of assessments
state_summary
states_map <- map_data("state")
state_summary$region <- tolower(state_summary$STATE)
# Get the state map data
states_map <- map_data("state")
# Debug: Check if there's a mismatch in state names
# This will print any state names from your data not found in the map data
setdiff(state_summary$region, unique(states_map$region))
# Merge the summarized data with the map data and check how many are NA after merge
map_data <- merge(states_map, state_summary, by = "region", all.x = TRUE)
table(is.na(map_data$assessments))
map_data
# Create the choropleth map
ggplot(map_data, aes(long, lat, group = group, fill = assessments)) +
geom_polygon(color = "white") +
scale_fill_gradient(low = "white", high = "blue", na.value = "grey") +  # Add this to handle NAs
coord_fixed(1.3) +
labs(fill = "Number of Assessments") +
ggtitle("Number of Assessments by State") +
theme_minimal()
# assess_data <- read_excel("path/to/IAC_Database_20240514.xlsx", sheet = "ASSESS")
state_summary <- joined_frames %>%
group_by(STATE) %>%
summarise(assessments = n(), .groups = 'drop')  # Count of assessments
state_summary
states_map <- map_data("state")
# Check the unique state names in both datasets
print(unique(state_summary$STATE))
print(unique(states_map$region))
# Create a lowercase version of the states for matching
state_summary$region <- tolower(state_summary$STATE)
states_map$region <- tolower(states_map$region)
# Identify mismatches
mismatches <- setdiff(state_summary$region, states_map$region)
if (length(mismatches) > 0) {
print("Mismatches found:")
print(mismatches)
} else {
print("No mismatches found, proceed to merge.")
}
# Assuming mismatches are resolved or none were found
map_data <- merge(states_map, state_summary, by = "region", all.x = TRUE)
# Check merge result
summary(map_data$assessments)
# Plot
choropleth_map <- ggplot(map_data, aes(long, lat, group = group, fill = assessments)) +
geom_polygon(color = "white") +
scale_fill_gradient(low = "white", high = "blue", na.value = "grey") +
coord_fixed(1.3) +
labs(fill = "Number of Assessments") +
ggtitle("Number of Assessments by State") +
theme_minimal()
print(choropleth_map)
print(unique(state_summary$STATE))
print(unique(states_map$region))
state_summary$region <- tolower(state_summary$STATE)
mismatches <- setdiff(state_summary$region, states_map$region)
if (length(mismatches) > 0) {
print("Mismatches found:")
print(mismatches)
} else {
print("No mismatches found, proceed to merge.")
}
